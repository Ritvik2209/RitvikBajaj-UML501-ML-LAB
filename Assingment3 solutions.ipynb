{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T09:18:42.278528Z",
     "start_time": "2025-08-27T09:18:01.920563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_house_data():\n",
    "    df = pd.read_csv('USA_Housing.csv')\n",
    "    print(\"House Dataset Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "def k_fold_cross_validation(X, y, k=5):\n",
    "    n = len(X)\n",
    "    fold_size = n // k\n",
    "    best_beta = None\n",
    "    best_r2 = -np.inf\n",
    "    results = []\n",
    "\n",
    "    for i in range(k):\n",
    "        start_idx = i * fold_size\n",
    "        end_idx = (i + 1) * fold_size if i < k - 1 else n\n",
    "\n",
    "        test_indices = list(range(start_idx, end_idx))\n",
    "        train_indices = list(range(0, start_idx)) + list(range(end_idx, n))\n",
    "\n",
    "        X_train = X.iloc[train_indices]\n",
    "        X_test = X.iloc[test_indices]\n",
    "        y_train = y.iloc[train_indices]\n",
    "        y_test = y.iloc[test_indices]\n",
    "\n",
    "        X_train_with_intercept = np.column_stack([np.ones(len(X_train)), X_train])\n",
    "        X_test_with_intercept = np.column_stack([np.ones(len(X_test)), X_test])\n",
    "\n",
    "        beta = np.linalg.inv(X_train_with_intercept.T @ X_train_with_intercept) @ X_train_with_intercept.T @ y_train\n",
    "        y_pred = X_test_with_intercept @ beta\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            'fold': i + 1,\n",
    "            'beta': beta,\n",
    "            'r2_score': r2\n",
    "        })\n",
    "\n",
    "        print(f\"Fold {i+1}: R² = {r2:.4f}\")\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_beta = beta\n",
    "\n",
    "    return results, best_beta, best_r2\n",
    "\n",
    "def gradient_descent(X, y, learning_rate=0.01, iterations=1000):\n",
    "    X_with_intercept = np.column_stack([np.ones(len(X)), X])\n",
    "    m, n = X_with_intercept.shape\n",
    "    beta = np.zeros(n)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_pred = X_with_intercept @ beta\n",
    "        cost = np.mean((y_pred - y) ** 2)\n",
    "        gradient = (2 / m) * X_with_intercept.T @ (y_pred - y)\n",
    "        beta -= learning_rate * gradient\n",
    "\n",
    "    return beta\n",
    "\n",
    "def question_1():\n",
    "\n",
    "    df = load_house_data()\n",
    "\n",
    "    X = df.drop('Price', axis=1)\n",
    "    y = df['Price']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    results, best_beta, best_r2 = k_fold_cross_validation(X_scaled, y)\n",
    "    print(f\"\\nBest R² Score: {best_r2:.4f}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    X_train_with_intercept = np.column_stack([np.ones(len(X_train)), X_train])\n",
    "    X_test_with_intercept = np.column_stack([np.ones(len(X_test)), X_test])\n",
    "\n",
    "    y_pred_test = X_test_with_intercept @ best_beta\n",
    "    final_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"Final Test R² Score: {final_r2:.4f}\")\n",
    "    return results, best_beta\n",
    "\n",
    "def question_2():\n",
    "\n",
    "    df = load_house_data()\n",
    "\n",
    "    X = df.drop('Price', axis=1)\n",
    "    y = df['Price']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "    learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "    best_lr = None\n",
    "    best_val_r2 = -np.inf\n",
    "    best_coefficients = None\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        coefficients = gradient_descent(X_train, y_train, lr, 1000)\n",
    "\n",
    "        X_val_with_intercept = np.column_stack([np.ones(len(X_val)), X_val])\n",
    "        X_test_with_intercept = np.column_stack([np.ones(len(X_test)), X_test])\n",
    "\n",
    "        y_val_pred = X_val_with_intercept @ coefficients\n",
    "        y_test_pred = X_test_with_intercept @ coefficients\n",
    "\n",
    "        val_r2 = r2_score(y_val, y_val_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Validation R²: {val_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "\n",
    "        if val_r2 > best_val_r2:\n",
    "            best_val_r2 = val_r2\n",
    "            best_lr = lr\n",
    "            best_coefficients = coefficients\n",
    "\n",
    "    print(f\"\\nBest Learning Rate: {best_lr}\")\n",
    "    print(f\"Best Validation R²: {best_val_r2:.4f}\")\n",
    "\n",
    "    return best_coefficients, best_lr\n",
    "\n",
    "def load_car_data():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "    columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "               \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
    "               \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
    "               \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
    "               \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
    "               \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "    df = pd.read_csv(url, names=columns, na_values='?')\n",
    "    print(\"Car Dataset Shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "def preprocess_car_data(df):\n",
    "    df = df.dropna(subset=['price'])\n",
    "\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col != 'price':\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    door_mapping = {'two': 2, 'four': 4}\n",
    "    cylinder_mapping = {'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12}\n",
    "\n",
    "    df['num_doors'] = df['num_doors'].map(door_mapping)\n",
    "    df['num_cylinders'] = df['num_cylinders'].map(cylinder_mapping)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['body_style', 'drive_wheels'], prefix=['body_style', 'drive_wheels'])\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    for col in ['make', 'aspiration', 'engine_location', 'fuel_type']:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    df['fuel_system'] = df['fuel_system'].apply(lambda x: 1 if 'pfi' in str(x).lower() else 0)\n",
    "    df['engine_type'] = df['engine_type'].apply(lambda x: 1 if 'ohc' in str(x).lower() else 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def question_3():\n",
    "\n",
    "    df = load_car_data()\n",
    "    df_processed = preprocess_car_data(df)\n",
    "\n",
    "    print(f\"Processed Dataset Shape: {df_processed.shape}\")\n",
    "\n",
    "    X = df_processed.drop('price', axis=1)\n",
    "    y = df_processed['price']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2_original = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Original Model R² Score: {r2_original:.4f}\")\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    print(f\"PCA Components: {pca.n_components_} (from {X.shape[1]} original features)\")\n",
    "\n",
    "    model_pca = LinearRegression()\n",
    "    model_pca.fit(X_train_pca, y_train)\n",
    "    y_pred_pca = model_pca.predict(X_test_pca)\n",
    "    r2_pca = r2_score(y_test, y_pred_pca)\n",
    "\n",
    "    print(f\"PCA Model R² Score: {r2_pca:.4f}\")\n",
    "\n",
    "    if r2_pca > r2_original:\n",
    "        print(\"PCA improved performance!\")\n",
    "    elif r2_pca < r2_original:\n",
    "        print(\"PCA reduced performance.\")\n",
    "    else:\n",
    "        print(\"PCA had no significant impact on performance.\")\n",
    "\n",
    "    return r2_original, r2_pca, pca.n_components_\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        results_q1, best_beta = question_1()\n",
    "        best_coeffs, best_lr = question_2()\n",
    "        r2_orig, r2_pca, n_components = question_3()\n",
    "\n",
    "        print(f\"Q1 - Best K-Fold R²: {max([r['r2_score'] for r in results_q1]):.4f}\")\n",
    "        print(f\"Q2 - Best Learning Rate: {best_lr}\")\n",
    "        print(f\"Q3 - Original R²: {r2_orig:.4f}, PCA R²: {r2_pca:.4f}\")\n",
    "        print(f\"Q3 - Dimensionality Reduction: {n_components} components\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find dataset file. {e}\")\n",
    "        print(\"Make sure 'USA_Housing.csv' is in your project directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "b00cad862f360a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUESTION 1: K-FOLD CROSS VALIDATION ===\n",
      "House Dataset Shape: (5000, 6)\n",
      "Columns: ['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population', 'Price']\n",
      "Fold 1: R² = 0.9176\n",
      "Fold 2: R² = 0.9203\n",
      "Fold 3: R² = 0.9152\n",
      "Fold 4: R² = 0.9209\n",
      "Fold 5: R² = 0.9138\n",
      "\n",
      "Best R² Score: 0.9209\n",
      "Final Test R² Score: 0.9147\n",
      "\n",
      "=== QUESTION 2: GRADIENT DESCENT WITH VALIDATION SET ===\n",
      "House Dataset Shape: (5000, 6)\n",
      "Columns: ['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population', 'Price']\n",
      "Learning Rate: 0.001, Validation R²: 0.6820, Test R²: 0.6490\n",
      "Learning Rate: 0.01, Validation R²: 0.9098, Test R²: 0.9148\n",
      "Learning Rate: 0.1, Validation R²: 0.9098, Test R²: 0.9148\n",
      "Learning Rate: 1, Validation R²: -inf, Test R²: -inf\n",
      "\n",
      "Best Learning Rate: 0.01\n",
      "Best Validation R²: 0.9098\n",
      "\n",
      "=== QUESTION 3: CAR PRICE PREDICTION WITH PREPROCESSING ===\n",
      "Car Dataset Shape: (205, 26)\n",
      "Processed Dataset Shape: (201, 32)\n",
      "Original Model R² Score: 0.8734\n",
      "PCA Components: 17 (from 31 original features)\n",
      "PCA Model R² Score: 0.8486\n",
      "PCA reduced performance.\n",
      "\n",
      "=== SUMMARY ===\n",
      "Q1 - Best K-Fold R²: 0.9209\n",
      "Q2 - Best Learning Rate: 0.01\n",
      "Q3 - Original R²: 0.8734, PCA R²: 0.8486\n",
      "Q3 - Dimensionality Reduction: 17 components\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
