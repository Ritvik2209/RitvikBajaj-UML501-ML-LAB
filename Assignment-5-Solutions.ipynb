{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb04d8ec",
   "metadata": {},
   "source": [
    "## Q1: Ridge Regression with Gradient Descent Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53471cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset with highly correlated features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "X = np.random.rand(n, 7)\n",
    "X[:, 1] = X[:, 0] + np.random.normal(0, 0.01, n)  # high correlation\n",
    "X[:, 2] = X[:, 0] - np.random.normal(0, 0.01, n)\n",
    "y = 3*X[:, 0] + 2*X[:, 1] - X[:, 2] + np.random.normal(0, 0.1, n)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8628168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Ridge Regression with Gradient Descent\n",
    "def ridge_gd(X, y, lr, reg, n_iter=1000):\n",
    "    m, n = X.shape\n",
    "    beta = np.zeros(n)\n",
    "    for _ in range(n_iter):\n",
    "        y_pred = X @ beta\n",
    "        grad = -2 * X.T @ (y - y_pred) / m + 2 * reg * beta\n",
    "        beta -= lr * grad\n",
    "    return beta\n",
    "# Try different learning rates and regularization parameters\n",
    "lrs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "regs = [1e-15, 1e-10, 1e-5, 1e-3, 0.1, 1, 10, 20]\n",
    "from sklearn.metrics import r2_score\n",
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "for lr in lrs:\n",
    "    for reg in regs:\n",
    "        beta = ridge_gd(X_scaled, y, lr, reg)\n",
    "        y_pred = X_scaled @ beta\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_params = (lr, reg)\n",
    "best_params, best_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b4194",
   "metadata": {},
   "source": [
    "## Q2: Hitters Dataset - Linear, Ridge, and LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess Hitters dataset\n",
    "df = pd.read_csv('Hitters.csv')  # Update with actual path\n",
    "df = df.dropna()\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "X = df.drop('Salary', axis=1)\n",
    "y = df['Salary']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be32b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Linear, Ridge, and LASSO regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "lin = LinearRegression().fit(X_train, y_train)\n",
    "ridge = Ridge(alpha=0.5748).fit(X_train, y_train)\n",
    "lasso = Lasso(alpha=0.5748).fit(X_train, y_train)\n",
    "y_pred_lin = lin.predict(X_test)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "r2_lin, r2_ridge, r2_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc1ff5",
   "metadata": {},
   "source": [
    "## Q3: Cross Validation for Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1906846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RidgeCV and LassoCV on Boston dataset\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "ridgecv = RidgeCV(alphas=[0.1, 1, 10, 100], cv=5).fit(X_scaled, y)\n",
    "lassocv = LassoCV(alphas=[0.1, 1, 10, 100], cv=5, max_iter=10000).fit(X_scaled, y)\n",
    "ridgecv.alpha_, lassocv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b6d7f",
   "metadata": {},
   "source": [
    "## Q4: Multiclass Logistic Regression (Iris Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-rest Multiclass Logistic Regression on Iris\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
    "model.fit(X, y)\n",
    "score = model.score(X, y)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
